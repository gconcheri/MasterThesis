{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of Flux-Free Kitaev Honeycomb lattice state\n",
    "## In HONEYCOMB LATTICE SPACE\n",
    "2 honeycombs\n",
    "\n",
    "N = 14 spins\n",
    "\n",
    "Hamiltonian: $H = -J_x \\sum_{\\langle i,j \\rangle_x} \\sigma_i^x \\sigma_j^x\n",
    "    -J_y \\sum_{\\langle i,j \\rangle_y} \\sigma_i^y \\sigma_j^y\n",
    "    -J_z \\sum_{\\langle i,j \\rangle_z} \\sigma_i^z \\sigma_j^z$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: prepare product state $|00..>$ of N spins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1091\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1190\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are doing this mapping: \n",
    "\n",
    "$\\ket{\\uparrow \\uparrow} = \\ket{00} , \\quad\\ket{\\downarrow \\downarrow} = \\ket{11} $\n",
    "\n",
    "\n",
    "![Graphene]()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16384, 1)\n"
     ]
    }
   ],
   "source": [
    "n_spins = 14\n",
    "e1 = sparse.csr_array([[1],[0]])\n",
    "psi = e1\n",
    "for _ in range(n_spins-1):\n",
    "    psi = sparse.kron(psi,e1, format='csr')\n",
    "\n",
    "print(psi.shape)\n",
    "\n",
    "\n",
    "assert psi.shape[0]== 2**14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "print(psi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify a representative qubit in each plaquette: we identify qubit 0 and 6\n",
    "\n",
    "We create operator that applies hadamard only on these two representative qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hadamard(qubit1, qubit2, n):\n",
    "    assert qubit1 < qubit2\n",
    "    Id = sparse.csr_array(np.eye(4))\n",
    "    H_small = sparse.csr_array([[1./np.sqrt(2), 0., 0., 1./np.sqrt(2)], [0., 1., 0., 0.], [0., 0., 1., 0.], [1./np.sqrt(2), 0., 0., -1./np.sqrt(2)]])\n",
    "    op_list = [Id]*n\n",
    "    op_list[qubit1] = H_small\n",
    "    op_list[qubit2] = H_small\n",
    "    \n",
    "    H = op_list[0]\n",
    "\n",
    "    for op in op_list[1:]:\n",
    "        H = sparse.kron(H,op, format='csr')\n",
    "    return H\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Computational (Python 3.12.8)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "qubit1 = 0\n",
    "qubit2 = 4\n",
    "H = Hadamard(qubit1,qubit2,n_spins)\n",
    "print(H.shape)\n",
    "psi1 = H @ psi.copy()\n",
    "\n",
    "print(psi1.shape)\n",
    "print(psi1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create op. that applies CNOT on each plaquette with representative qubits as control qubits and all other qubits of plaquette as target ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNOT(qubit1, qubit2, n, l): #l = spins per plaquette, n = tot spins\n",
    "    assert qubit1 < 3\n",
    "    assert 3 < qubit2\n",
    "    # Id = sparse.csr_array(np.eye(2))\n",
    "    # X = sparse.csr_array([[0.,1.],[1.,0.]])\n",
    "    # Proj_0 = sparse.csr_array([[1.,0.],[0.,0.]]) #|0><0|\n",
    "    # Proj_1 = sparse.csr_array([[0.,0.],[0.,1.]]) #|1><1|\n",
    "    \n",
    "    newId = sparse.csr_array(np.eye(2**(n-2*l)))\n",
    "    CNOT_p1 = sparse.kron(plaquetteCNOT(qubit1,l),newId,'csr')\n",
    "    CNOT_p2 = sparse.kron(newId,plaquetteCNOT(qubit2-l+1,l), 'csr') #we map qubit 3 -> 0, 4->1, 5->2, 6->3\n",
    "    # even if geometry is not conserved, it still works because CNOT applied on this \n",
    "    #sequence of hilbert spaces in this order does not depend on geometry!\n",
    "    # print(CNOT_p2 @ CNOT_p1)\n",
    "    # print(CNOT_p1 @ CNOT_p2)\n",
    "    assert np.array_equal((CNOT_p2 @ CNOT_p1).toarray(), (CNOT_p1 @ CNOT_p2).toarray()), \"Sparse arrays are not equal\"\n",
    "    return CNOT_p2 @ CNOT_p1\n",
    "\n",
    "def plaquetteCNOT(qubit, l):\n",
    "    Id = sparse.csr_array(np.eye(4))\n",
    "    X = np.zeros((4,4))\n",
    "    X[0,3] = 1\n",
    "    X[3,0] = 1\n",
    "    X = sparse.csr_array(X)\n",
    "    print(X)\n",
    "    \n",
    "    Proj_0 = np.zeros((4,4)) #|00><00|\n",
    "    Proj_0[0,0] = 1\n",
    "    Proj_0 = sparse.csr_array(Proj_0)\n",
    "    Proj_1 = np.zeros((4,4)) #|11><11|\n",
    "    Proj_1[3,3] = 1\n",
    "    Proj_1 = sparse.csr_array(Proj_1)\n",
    "\n",
    "    op_list_id = [Id]*l\n",
    "    op_list_id[qubit] = Proj_0\n",
    "\n",
    "    op_list_x = [X]*l\n",
    "    op_list_x[qubit] = Proj_1\n",
    "\n",
    "    CNOT1 = op_list_id[0]\n",
    "    CNOT2 = op_list_x[0]\n",
    "\n",
    "    for op1, op2 in zip(op_list_id[1:],op_list_x[1:]):\n",
    "        CNOT1 = sparse.kron(CNOT1, op1, 'csr')\n",
    "        CNOT2 = sparse.kron(CNOT2, op2, 'csr')\n",
    "    return CNOT1 + CNOT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (1, 1)\t0.0\n",
      "  (2, 3)\t0.0\n",
      "  (3, 2)\t1.0\n"
     ]
    }
   ],
   "source": [
    "#TEST FOR plaquetteCNOT: it works\n",
    "CNOT_test = plaquetteCNOT(0,2)\n",
    "print(CNOT_test*([1,0,1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.5 0.  0.  0.  0.  0.\n",
      " 0.  0. ]\n"
     ]
    }
   ],
   "source": [
    "CNOT_op = CNOT(qubit1, qubit2, n_spins, 4)\n",
    "#print(CNOT_op.toarray())\n",
    "psi2 =  CNOT_op @ psi1.copy()\n",
    "#print(psi1.shape)\n",
    "#print(CNOT_op.shape)\n",
    "#print(psi2.shape)\n",
    "print(psi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to convert this state from toric code space to Honeycomb space! Mapping written on ipad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0  15 119 120]\n",
      "[0.5 0.5 0.5 0.5]\n",
      "Original Sparse Array:\n",
      "  (0, 0)\t0.4999999999999999\n",
      "  (15, 0)\t0.4999999999999999\n",
      "  (119, 0)\t0.4999999999999999\n",
      "  (120, 0)\t0.4999999999999999\n",
      "\n",
      "New Sparse Array:\n",
      "  (0, 0)\t0.4999999999999999\n",
      "  (255, 0)\t0.4999999999999999\n",
      "  (16191, 0)\t0.4999999999999999\n",
      "  (16320, 0)\t0.4999999999999999\n"
     ]
    }
   ],
   "source": [
    "# Example 1D sparse array\n",
    "n = n_spins  # Length of binary representation\n",
    "\n",
    "sparse_array = psi2.copy()\n",
    "\n",
    "# Step 1: Extract non-zero positions\n",
    "non_zero_positions = sparse_array.nonzero()[0]\n",
    "print(non_zero_positions)\n",
    "\n",
    "# Step 2: Convert positions to binary strings of length n\n",
    "binary_positions = [f\"{pos:0{n}b}\" for pos in non_zero_positions]\n",
    "\n",
    "# Step 3: Extract positions of '1's and compute new positions\n",
    "new_binary_positions = []\n",
    "\n",
    "for binary in binary_positions:\n",
    "    ones_positions = [i for i, bit in enumerate(binary) if bit == '1']\n",
    "    new_binary = ['0'] * (2 * n)\n",
    "\n",
    "    for pos in ones_positions:\n",
    "        new_binary[2 * pos] = '1'  # Place '1' at 2 * pos\n",
    "        if 2 * pos + 1 < len(new_binary):  # Ensure within bounds\n",
    "            new_binary[2 * pos + 1] = '1'  # Place '1' at 2 * pos + 1\n",
    "\n",
    "    new_binary_positions.append(''.join(new_binary))\n",
    "\n",
    "# Step 4: Convert new binary numbers to integers\n",
    "new_positions = [int(binary, 2) for binary in new_binary_positions]\n",
    "\n",
    "# Step 5: Map original data values to new positions\n",
    "data = sparse_array.data  # Extract the non-zero values from the original sparse array\n",
    "print(data)\n",
    "\n",
    "# Step 6: Create new sparse array\n",
    "new_sparse_array = sparse.csr_array((data, (new_positions, [0] * len(new_positions))), shape=(2**(2*n), 1))\n",
    "\n",
    "# Print results\n",
    "print(\"Original Sparse Array:\")\n",
    "print(sparse_array)\n",
    "\n",
    "print(\"\\nNew Sparse Array:\")\n",
    "print(new_sparse_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16384\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
